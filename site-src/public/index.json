[{"categories":["ibmcloud"],"contents":"These examples are broken up in to two sections:\n Cloud IaaS (Classic Infrastructure)   Note: The following examples use jq to parse the json output returned by the IBM Cloud CLIs output flag. If you do not have jq installed or cannot install it, you can use IBM Cloud Shell which includes jq by default.\n    Search Cloud Resources     Search for resource by name  Search for a cloud resource with the name devcluster:\n1  ibmcloud resource search \u0026#39;name:devcluster\u0026#39;      Search by resource name and return CRN  Perform the same search, but use jq to just return the CRN of the resource:\n1 2  ibmcloud resource search \u0026#39;name:devcluster\u0026#39; --output json \\  | jq -r \u0026#39;.items[].crn\u0026#39;      Search by resource tag  Search for all cloud resources with the tag ryantiffany\n1  ibmcloud resource search \u0026#39;tags:ryantiffany\u0026#39; --output json      Search by resource tag and just return resource names  Search for all cloud resources with the tag env:2022-cde-lab and return just the items name:\n1 2  ibmcloud resource search \u0026#39;tags:\u0026#34;env:2022-cde-lab\u0026#34;\u0026#39; --output json \\  | jq -r \u0026#39;.items[].name\u0026#39;   Example Output\n1 2 3 4 5 6 7 8 9 10 11  ibmcloud resource search \u0026#39;tags:\u0026#34;env:2022-cde-lab\u0026#34;\u0026#39; --output json \\  | jq -r \u0026#39;.items[].name\u0026#39; 2022-cde-lab-cos-instance continuous-delivery-2022-cde-lab pubgw-au-syd-1-2022-cde-lab subnet-au-syd-1-2022-cde-lab pubgw-au-syd-2-2022-cde-lab subnet-au-syd-2-2022-cde-lab pubgw-au-syd-3-2022-cde-lab subnet-au-syd-3-2022-cde-lab vpc-au-syd-2022-cde-lab      Search by resource tag and return resource type  Find all the cloud resources with the tag env:2022-cde-lab and return their resource type:\n1 2  ibmcloud resource search \u0026#39;tags:\u0026#34;env:2022-cde-lab\u0026#34;\u0026#39; --output json \\  | jq -r \u0026#39;.items[].type\u0026#39;      Search Classic Infrastructure  1  ibmcloud resource search -p classic-infrastructure --output json      Search classic infrastructure by tag  1 2  ibmcloud resource search \u0026#34;tagReferences.tag.name:ryantiffany\u0026#34; \\  -p classic-infrastructure --output json      Search classic infrastructure by tag and return resource types  1 2 3  ibmcloud resource search \u0026#34;tagReferences.tag.name:ryantiffany\u0026#34; \\  -p classic-infrastructure --output json \\  | jq -r \u0026#39;.items[].resourceType\u0026#39;      Search by tag and filter by resource type  Search for resources with the tag ryantiffany and use the _objectType filter to just return the Classic Virtual Servers:\n1 2 3  ibmcloud resource search \u0026#34;tagReferences.tag.name:ryantiffany \\ _objectType:SoftLayer_Virtual_Guest\u0026#34; \\  -p classic-infrastructure --output json      Search IaaS Virtual instances by Tag and return FQDNs  Search for resources with the tag ryantiffany and use the _objectType filter and jq to just return the FQDN of the servers:\n1 2 3 4  ibmcloud resource search \u0026#34;tagReferences.tag.name:ryantiffany \\ _objectType:SoftLayer_Virtual_Guest\u0026#34; \\  -p classic-infrastructure --output json \\  | jq -r \u0026#39;.items[].resource.fullyQualifiedDomainName\u0026#39;      Search IaaS Virtual instances by Tag and return instance ID\u0026rsquo;s  1 2 3  ibmcloud resource search \u0026#34;tagReferences.tag.name:ryantiffany \\ _objectType:SoftLayer_Virtual_Guest\u0026#34; \\  -p classic-infrastructure --output json | jq -r \u0026#39;.items[].resource.id\u0026#39;   ","date":"Mar 05","permalink":"https://rst.quest/post/resource-search/","tags":["search","cli"],"title":"Resource search using the IBM Cloud CLI"},{"categories":["ibmcloud"],"contents":"   Overview  This guide will show you how to use the experimental IBM Code Engine to build a container image from a Source control repository. Behind the scenes Code Engine will use Tekton pipelines to pull our source code from a Github repository and then create a container image using the supplied Docker file. After the build is complete Code Engine will push the new container image in to the IBM Cloud Container Registry.\nNOTE: Code Engine is currently an experimental offering and all resources are deleted every 7 days.\n   Start a session in IBM Cloud Shell  In the IBM Cloud console, click the IBM Cloud Shell icon\n.\nA session starts and automatically logs you in through the IBM Cloud CLI.\n   Target Resource Group  In oder to interact with the Code Engine CLI we first need to target the Resource Group where the Code Engine project will be created:\n1  $ ibmcloud target -g \u0026lt;Your Resource Group\u0026gt;      Create a Code Engine Project  The first step is to create a Code Engine project.\n Keep in mind during the Beta phase you are limited to one Code Engine project per region. If you already have a Code Engine project you can simply target that project using the command ibmcloud ce project target -n \u0026lt;name of project\u0026gt;\n We\u0026rsquo;ll specify the --target option to automatically have the Code Engine cli target our new project:\n$ ibmcloud ce project create -n \u0026lt;Project Name\u0026gt; --target The project creation can take a few minutes, but when it completes you should see something like this:\n1 2 3 4 5  $ ibmcloud ce project create -n ce-demo-project --target Creating project \u0026#39;ce-demo-project\u0026#39;... Waiting for project \u0026#39;ce-demo-project\u0026#39; to be in ready state... Now selecting project \u0026#39;ce-demo-project\u0026#39;. OK      Create an API Key for Code Engine for Registry Access  As part of our Build process we are going be pulling a public Github repo but then pushing the built container in to IBM Cloud Container Registry. In order for our Code Engine project to be able to push to the registry we\u0026rsquo;ll need to create an API key.\n1  $ ibmcloud iam api-key-create \u0026lt;Project Name\u0026gt;-cliapikey -d \u0026#34;API Key for talking to Image registry from Code Engine\u0026#34; --file key_file      Create Code Engine Registry Secret  With our API key created, we will now add the IBM Cloud Container Registry to Code Engine. When using the IBM Container Registry the username will always be iamapikey. If you would like to push to an alternate IBM Container Registry endpoint update the --server flag accordingly.\n1 2 3  $ export CR_API_KEY=`jq -r \u0026#39;.apikey\u0026#39; \u0026lt; key_file` $ ibmcloud ce registry create --name ibmcr --server us.icr.io --username iamapikey --password \u0026#34;${CR_API_KEY}\u0026#34;   You can view all of your registry secrets by running the command: ibmcloud ce registry list.\n1 2 3 4 5 6 7  $ ibmcloud ce registry list Project \u0026#39;demo-rt\u0026#39; and all its contents will be automatically deleted 7 days from now. Listing image registry access secrets... OK Name Age ibmcr 11s      Create Code Engine Build Definition  With the Registry access added we can now create our Build definition. If you do not already have a Container namespace to push images to, please follow [this guide to create one.\n1  $ ibmcloud ce build create --name go-app-example-build --source https://github.com/greyhoundforty/ce-build-example-go --strategy kaniko --size medium --image us.icr.io/\u0026lt;namespace\u0026gt;/go-app-example --registry-secret ibmcr   The breakdown of the command:\n name: The name of the build definition source: The Source control repository where our code lives strategy: The build strategy we will use to build the image. In this case since our repository has a Dockerfile we will use kaniko size: The size of the build defines how CPU cores, memory, and disk space are assigned to the build image: The Container Registry namespace and image name to push our built container image registry-secret: The Container Registry secret that allows Code Engine to push and pull images     Submit the Build Job  Before the Build run is submitted (the actual process of building the container image), we’ll want to target the underlying Kubernetes cluster that powers Code Engine. This will allow us to see the pods that are spun up for the build as well as track it’s progress. To have kubctl within Cloud Shell target our cluster run the following command: ibmcloud ce project target -n \u0026lt;Name of Project\u0026gt; -k\nYou should see output similar to this:\n1 2 3 4  $ ibmcloud ce project target -n demo-rt -k Selecting project \u0026#39;demo-rt\u0026#39;... Added context for \u0026#39;demo-rt\u0026#39; to the current kubeconfig file. OK   With kubectl properly configured we can now launch the actual build of our container image using the buildrun command. We specify the build definition we created previously with the --build flag:\n1  $ ibmcloud ce buildrun submit --name go-app-buildrun-v1 --build go-app-example-build   You can check the status of the build run using the command ibmcloud ce buildrun get --name \u0026lt;Name of build run\u0026gt;\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  $ ibmcloud ce buildrun get --name go-app-buildrun-v1 Project \u0026#39;demo-rt\u0026#39; and all its contents will be automatically deleted 7 days from now. Getting build run \u0026#39;go-app-buildrun-v1\u0026#39;... OK Name: go-app-buildrun-v1 ID: d378e865-ecf4-4e26-932d-acb437eef0ef Project Name: demo-rt Project ID: ab07a001-9a77-4fd8-82e8-d4f8395ad735 Age: 36s Created: 2020-09-23 09:13:33 -0500 CDT Status: Reason: Running Registered: Unknown Instances: Name Running Status Restarts Age go-app-buildrun-v1-xpqfq-pod-hqchd 2/4 Running 0 34s   You can also check on the status of the Kubernetes pods by running kubectl get pods\n1 2 3  $ kubectl get pods NAME READY STATUS RESTARTS AGE go-app-buildrun-v1-xpqfq-pod-hqchd 2/4 Running 0 41s   If the build completes successfully the pods will show Completed and the build run will show Succeeded\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  $ kubectl get pods NAME READY STATUS RESTARTS AGE go-app-buildrun-v1-xpqfq-pod-hqchd 0/4 Completed 0 4m10s $ ibmcloud ce buildrun get --name go-app-buildrun-v1 Project \u0026#39;demo-rt\u0026#39; and all its contents will be automatically deleted 7 days from now. Getting build run \u0026#39;go-app-buildrun-v1\u0026#39;... OK Name: go-app-buildrun-v1 ID: d378e865-ecf4-4e26-932d-acb437eef0ef Project Name: demo-rt Project ID: ab07a001-9a77-4fd8-82e8-d4f8395ad735 Age: 4m26s Created: 2020-09-23 09:13:33 -0500 CDT Status: Reason: Succeeded Registered: True Instances: Name Running Status Restarts Age go-app-buildrun-v1-xpqfq-pod-hqchd 0/4 Succeeded 0 4m24s   ","date":"Mar 05","permalink":"https://rst.quest/post/container-image-build-ce/","tags":["code-engine","serverless","containers"],"title":"Container image builds using IBM Code Engine"},{"categories":["ibmcloud"],"contents":"   Overview  In this guide I will show you how to sync IBM Cloud Object Storage buckets between accounts using Code Engine. Code Engine provides a platform to unify the deployment of all of your container-based applications on a Kubernetes-based infrastructure. The Code Engine experience is designed so that you can focus on writing code without the need for you to learn, or even know about, Kubernetes.\n   Preparing Accounts  We will be using Cloud Shell to generate Service IDs and Object Storage credentials for both the source and destination accounts.\nWe will also be creating a Service ID on the both accounts. A service ID identifies a service or application similar to how a user ID identifies a user. We can assign specific access policies to the service ID that restrict permissions for using specific services: in this case it gets read-only access to an Object Storage bucket on the Source Account and write access an Object Storage bucket on the Destination Account.\n   Source Account  Launch a Cloud Shell session on the Source Account to begin generating our Object Storage access credentials.\n   Create Service ID  Create a new service ID for the source account.\n1  ibmcloud iam service-id-create SERVICE_ID_NAME --description \u0026#34;Service ID for read-only access to bucket\u0026#34;      Create Reader access policy for newly created Service ID  Now we will limit the scope of this service ID to have read only access to our source Object Storage bucket.\n SERVICE_ID: The ID of the Service ID created in the previous step. ICOS_SERVICE_INSTANCE_ID: The GUID of the Cloud Object Storage instance on the source account. You can retrieve this with the command: ibmcloud resource service-instance \u0026lt;name of icos instance\u0026gt; SOURCE_BUCKET_NAME: The name of the source account bucket that we will sync with the destination bucket.  1 2 3  ibmcloud iam service-policy-create SERVICE_ID --roles Reader \\ --service-name cloud-object-storage --service-instance ICOS_SERVICE_INSTANCE_ID \\ --resource-type bucket --resource SOURCE_BUCKET_NAME      Generate HMAC credentials tied to our service ID  In order for the Minio client to talk to each Object Storage instance it will need HMAC credentials (Access Key and Secret Key in S3 parlance).\n SERVICE_ID: The ID of the Service ID created in the previous step. ICOS_SERVICE_INSTANCE_ID: The GUID of the Cloud Object Storage instance on the source account. SERVICE_ID_KEY_NAME: The name of the Service ID credentials to create.  1 2  $ ibmcloud resource service-key-create SERVICE_ID_KEY_NAME Reader --instance-id ICOS_SERVICE_INSTANCE_ID \\ --service-id SERVICE_ID --parameters \u0026#39;{\u0026#34;HMAC\u0026#34;:true}\u0026#39;   Important Outputs: Take note of the output from the Serice Key output. These values will be used when creating our Code Engine Job.\n access_key_id will be used as the variable SOURCE_ACCESS_KEY secret_access_key will be used as the variable SOURCE_SECRET_KEY      Destination Account  Launch a Cloud Shell session on the Source Account to begin generating our Object Storage access credentials.\nCreate Service ID\n1  $ ibmcloud iam service-id-create SERVICE_ID_NAME --description \u0026#34;Service ID for write access to destination account bucket\u0026#34;   Inputs:\n  SERVICE_ID_NAME: The name for the Service ID on the source account.   **Create Reader access policy for newly created service ID: **\nNow we will add a Writer policy to our destination bucket bound to the Service ID.\n1 2  $ ibmcloud iam service-policy-create SERVICE_ID --roles Writer --service-name cloud-object-storage \\ --service-instance ICOS_SERVICE_INSTANCE_ID --resource-type bucket --resource DESTINATION_BUCKET_NAME   Inputs:\n  SERVICE_ID: The ID of the Service ID created in the previous step. ICOS_SERVICE_INSTANCE_ID: The GUID of the Cloud Object Storage instance on the source account. You can retrieve this with the command: ibmcloud resource service-instance \u0026lt;name of icos instance\u0026gt; DESTINATION_BUCKET_NAME: The name of the source account bucket that we will sync with the destination bucket.   Generate HMAC credentials tied to our service ID:\nWe\u0026rsquo;ll follow the same procedure as last time to generate the HMAC credentials, but this time on the destination account.\n1 2  $ ibmcloud resource service-key-create SERVICE_ID_KEY_NAME Reader --instance-id ICOS_SERVICE_INSTANCE_ID \\ --service-id SERVICE_ID --parameters \u0026#39;{\u0026#34;HMAC\u0026#34;:true}\u0026#39;   Inputs:\n  SERVICE_ID: The ID of the Service ID created in the previous step. ICOS_SERVICE_INSTANCE_ID: The GUID of the Cloud Object Storage instance on the source account. SERVICE_ID_KEY_NAME:   Important Outputs: Take note of the output from the Serice Key output. These values will be used when creating our Code Engine Job.\n  access_key_id will be used as the variable DESTINATION_ACCESS_KEY secret_access_key will be used as the variable DESTINATION_SECRET_KEY       Create Code Engine Project  Target Resource Group:\nOn the account where you will deploy and run the Code Engine job to sync the buckets jump back in to Cloud Shell. In order to create our Code Engine project we need to make sure that our cloud shell session is targeting the correct resource group.\n1  $ ibmcloud target -g RESOURCE_GROUP   Inputs:\n  RESOURCE_GROUP: Name of the Resource Group to assign to Code Engine Project.   Create Code Engine Project: With the correct Resource Group set, we can now create our Code Engine project. We add the --target flag to ensure that future Code Engine commands are targeting the correct project.\n$ ibmcloud ce project create -n PROJECT_NAME --target Inputs:\n  PROJECT_NAME: Name of the Code Engine Project.      (Optional) Create Docker container via Code Engine  The default image used to sync the buckets is greyhoundforty/mcsync:latest. If you would like to build the container yourself and stick it in to IBM Cloud Container Registry fork this repository, update the Dockerfile if needed, and then use Code Engine to build the image as outlined below.\nCreate Code Engine Repository Secret:\nIn order to push our container image in to IBM Cloud Container Registry we need to first set up a Code Engine registry secret.\n1 2  ibmcloud ce registry create --name REGISTRY_SECRET_NAME --username iamapikey \\  --password IBMCLOUD_API_KEY --email YOUR_IBM_ACCOUNT_EMAIL --server ICR_ENDPOINT   Inputs:\n  REGISTRY_SECRET_NAME: The name of the Code Engine Registry Secret. IBMCLOUD_API_KEY: The IBM Cloud API Key for your account. YOUR_IBM_ACCOUNT_EMAIL: The email associated with your IBM Account. ICR_ENDPOINT: The IBM Container Registry Endpoint to use. See full list   Create Container Build:\n1 2  ic ce build create --name BUILD_NAME --image us.icr.io/NAMESPACE/CONTAINER_NAME:1 --source FORKED_REPO_URL \\  --rs REGISTRY_SECRET_NAME --size small   Inputs:\n  BUILD_NAME: The name of the build job. NAMESPACE: The IBM Container Registry Namespace where the image will be stored. See this guide if you need to create a namespace. CONTAINER_NAME: The name of the container. FORKED_REPO_URL: The Github URL for the forked version of the sync container. REGISTRY_SECRET_NAME: The name of the Container Registry Secreate created in the previous step.   Run container build:\n1  ibmcloud ce buildrun submit --build BUILD_NAME   Inputs:\n  BUILD_NAME: The name of the build job created in the previous step.       Deploy Sync Environment  Clone this repository:\n1 2  git clone https://github.com/cloud-design-dev/code-engine-minio-sync.git cd code-engine-minio-sync   Copy variables.example to .env:\n1  cp variables.example .env   **Edit .env to match your environment: **\nSee inputs for available options.\nOnce updated source the file for use in our session:\n1  source .env   Create Code Engine Secret:\nibmcloud ce secret create --name CODE_ENGINE_SECRET --from-literal SOURCE_ACCESS_KEY=\u0026#34;${SOURCE_ACCESS_KEY}\u0026#34; \\ --from-literal SOURCE_SECRET_KEY=\u0026#34;${SOURCE_SECRET_KEY}\u0026#34; --from-literal SOURCE_REGION=\u0026#34;${SOURCE_REGION}\u0026#34; \\ --from-literal SOURCE_BUCKET=\u0026#34;${SOURCE_BUCKET}\u0026#34; --from-literal DESTINATION_REGION=\u0026#34;${DESTINATION_REGION}\u0026#34; \\ --from-literal DESTINATION_ACCESS_KEY=\u0026#34;${DESTINATION_ACCESS_KEY}\u0026#34; --from-literal DESTINATION_SECRET_KEY=\u0026#34;${DESTINATION_SECRET_KEY}\u0026#34; \\ --from-literal DESTINATION_BUCKET=\u0026#34;${DESTINATION_BUCKET}\u0026#34; Inputs:\n  CODE_ENGINE_SECRET: Name of the Code Engine Secret. All other variables are picked up from our .env file.   Create Code Engine Job:\nIf you created your own version of the container image as outlined above you will need to update the command and replace greyhoundforty/mcsync:latest with your image.\n1  ibmcloud ce job create --name JOB_NAME --image greyhoundforty/mcsync:latest --env-from-secret CODE_ENGINE_SECRET   Inputs:\n  JOB_NAME: The name of the Code Engine job. CODE_ENGINE_SECRET: Name of the Code Engine Secret. All other variables are picked up from our .env file.   Submit Code Engine Job:\n1  ibmcloud ce jobrun submit --job JOB_NAME   Inputs:\n  JOB_NAME: The name of the Code Engine job.   Check the status of the job:\nDepending on the size and number of objects that you are syncing the job could take a bit of time. You can check on the status of the job run by issuing the command:\n1  ibmcloud ce jobrun get --name JOB_NAME   ","date":"Mar 05","permalink":"https://rst.quest/post/cross-account-sync-ce/","tags":["code-engine","serverless","object-storage"],"title":"Cross account Object Storage bucket sync with Code Engine"},{"categories":["ibmcloud"],"contents":"   Cloud Shell  IBM Cloud Shell is a free service that gives you complete control of your cloud resources, applications, and infrastructure, from any web browser. It’s instantly accessible from your free IBM Cloud account—no other installation is needed. In the IBM Cloud console, click the IBM Cloud Shell icon . A session starts and automatically logs you in through the IBM Cloud CLI. You can open up to five concurrent sessions, which operate independently so you can work with different resources, regions, and accounts at once.\n Note: Your Cloud Shell workspace includes 500 MB of temporary secure storage, which you can access through your personal home directory, /home/\u0026lt;user-name\u0026gt;. If you\u0026rsquo;re idle in Cloud Shell for over an hour, your files and data are removed.\n ","date":"Mar 05","permalink":"https://rst.quest/post/cloud-shell/","tags":["cloud-shell"],"title":"Getting started with IBM Cloud Shell"},{"categories":["ibmcloud"],"contents":"   Overview  The VPC plugin allows you to interact with your VPCs, Subnets, Gateways, and more that are running in the IBM Cloud. In this guide I will show how to install the plugin and use it to list, query, and interact with the resources that are deployed as part of your Virtual Private Cloud.\n Note: The following examples use jq to parse the json output returned by the IBM Cloud CLIs output flag. If you do not have jq installed or cannot install it, you can use IBM Cloud Shell which includes jq by default.\n    Installing the plugin  If the pluging is not already installed you can install it using the following command:\n1  ibmcloud plugin update vpc-infrastructure   To verify the plugin is installed, run the following command: ibmcloud is regions. This will list the available regions where VPCs can be deployed.\n   VPCs  In order to interact with VPC resources you will need to target a VPC region. For instance if I wanted to look up my VPC resources in the us-south region I would set that in the CLI with the following command: ibmcloud target -r us-south.\n   List VPCs and return names and IDs  List all of the VPCs in the targetted region and use jq to return just the names and IDs:\n1  ibmcloud is vpcs --output json | jq -r \u0026#39;.[] | .name, .id\u0026#39;   Example Output\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  ibmcloud is vpcs --output json | jq -r \u0026#39;.[] | .name, .id\u0026#39; eric-vpxc r006-5c3fccad-xxxxxxxxxxx jb-vpc r006-9aae556c-xxxxxxxxxxx khurst r006-f4aaa5ad-xxxxxxxxxxx normangen2 r006-d9316884-xxxxxxxxxxx russelldallastest r006-65c1d331-xxxxxxxxxxx russellmigtest r006-ddf4d12f-xxxxxxxxxxx      Subnet     Get all Subnets in a VPC and return their ID and Name   VPC_NAME: The name of the VPC where the subnets reside  1  ic is subnets --output json | jq -r \u0026#39;.[] | select(.vpc.name==\u0026#34;VPC_NAME\u0026#34;) | .name,.id\u0026#39;      Images     Import custom image in to VPC    CUSTOM_IMAGE_NAME: The name assigned to the imported image IMAGE: The file name of the qcow2 image OS_NAME: The IBM Cloud equivalent OS Name. See here for supported options. RESOURCE_GROUP_ID: The resource group ID for the imported image   1  ibmcloud is image-create CUSTOM_IMAGE_NAME --file cos://region/bucket/IMAGE --os-name OS_NAME --resource-group-id RESOURCE_GROUP_ID      Instances  Examples for interacting with VPC compute instances\n   Get Windows instance password   INSTANCE_ID: The compute instance ID  1  ibmcloud is instance-initialization-values INSTANCE_ID --private-key @/path/to/private_key      Get primary IP from instance   INSTANCE_ID: The compute instance ID  1  ibmcloud is instance INSTANCE_ID --json | jq -r \u0026#39;.primary_network_interface.primary_ipv4_address\u0026#39;      Grab ID of compute instance based on name   NAME_OF_INSTANCE: The name of the compute instance  1  ibmcloud is instances --output json | jq -r \u0026#39;.[] | select(.name==\u0026#34;NAME_OF_INSTANCE\u0026#34;) | .id\u0026#39;      Find all networking interfaces attached to instance and return their name and ID   INSTANCE_ID: The compute instance ID  1  ibmcloud is in-nics INSTANCE_ID --output json | jq -r \u0026#39;.[] | .name,.id\u0026#39;      Find the floating IP attached to a specific compute instance   INSTANCE_ID: The compute instance ID  1  ibmcloud is instance INSTANCE_ID --output json | jq -r \u0026#39;.network_interfaces[].floating_ips[].id\u0026#39;      Finding Names and IDs     Finding IBM Image OS Names  You can run the following command to list the supported OS Names:\n1  ibmcloud is images --visibility public --json | jq -r \u0026#39;.[] | select(.status==\u0026#34;available\u0026#34;) | .operating_system.name\u0026#39;   ","date":"Mar 05","permalink":"https://rst.quest/post/vpc/","tags":["virtual-private-cloud","cli"],"title":"Using the IBM Cloud VPC CLI Plugin"},{"categories":["ibmcloud"],"contents":"   Overview  Examples of interacting with the IBM Cloud Object Storage CLI Plugin.\n   Prerequisites  Requires the cos plugin to be installed.\n   Configure cos plugin to use your object storage instance   NAME_OF_COS_INSTANCE: The name of the existing Object Storage instance to interact with  1  ibmcloud cos config crn --crn $(ibmcloud resource service-instance NAME_OF_COS_INSTANCE --output json | jq -r \u0026#39;.[].id\u0026#39;)      Upload object to object storage bucket  1 2  ibmcloud cos upload --bucket NAME_OF_BUCKET --key NAME_FOR_OBJECT \\ --file /path/to/object --region ICOS_REGION      Create HMAC credentials for S3 clients  1  ibmcloud resource service-key-create NAME_OF_SERVICE_KEY Writer --instance-name NAME_OF_COS_INSTANCE --parameters \u0026#39;{\u0026#34;HMAC\u0026#34;:true}\u0026#39;   ","date":"Mar 05","permalink":"https://rst.quest/post/icos/","tags":["object-storage","cli"],"title":"Using the Object Storage CLI Plugin"},{"categories":null,"contents":"","date":"Jan 01","permalink":"https://rst.quest/articles/","tags":null,"title":"Articles"}]